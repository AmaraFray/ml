data = {
    "KNN" : {
        "imp" : "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.datasets import load_breast_cancer",
        "data" : "dataset=load_breast_cancer()\nX_train,X_test,Y_train,Y_test = train_test_split(dataset['data'],dataset['target'], random_state=1984)",
        "model" : """
training_accuracy=[]
test_accuracy=[]
K=range(1,15)
for number_of_neighbors in K:
  KNN=KNeighborsClassifier(n_neighbors=number_of_neighbors)
  KNN.fit(X_train,Y_train)
  training_accuracy.append(KNN.score(X_train,Y_train))
  test_accuracy.append(KNN.score(X_test,Y_test))
  pred = KNN.predict(X_test)
  acc = accuracy_score(Y_test, pred)
  print("K value = {}\t Accuracy = {}".format(number_of_neighbors,acc))
                  """,
        "plot" : """plt.plot(K,training_accuracy, label="Accuracy in the training dataset")\nplt.plot(K,test_accuracy, label="Accuracy in the testing dataset")\nplt.ylabel("Accuracy")\nplt.xlabel("K value")\nplt.legend()""",
    },
    "DT" : {
        "imp":"""
import pandas as pd
import numpy as np

from sklearn.datasets import load_iris
from sklearn import metrics
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier

import matplotlib.pyplot as plt
        """,
        "data" : """
data = load_iris()

df = pd.DataFrame(data.data, columns=data.feature_names) 
X = df.copy()
df['target'] = data.target
Y = df['target']
        """,
        "model" : """
dtree = DecisionTreeClassifier()
# id3_tree = DecisionTreeClassifier(criterion = 'entropy')
# cart_tree = DecisionTreeClassifier(criterion = 'gini')
fitTree = dtree.fit(X, Y)
tree.plot_tree(fitTree, feature_names=list(df.columns))
y_pred = dtree.predict(X)
        """,
        "plot" : """
confusion_matrix = metrics.confusion_matrix(Y, y_pred)
cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = np.unique(y_pred))

plt.figure(figsize=(15,15))
cm_display.plot()

plt.show()
        """
    },
    "SVM" : {
        "imp" : """
from sklearn.svm import SVC
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV
        """,
        "data" : """
X = np.random.randn(20, 2)
y = [0 if x[0] + x[1] < 0 else 1 for x in X]

plt.scatter(X[:, 0], X[:, 1], c=y)
plt.show()

svc = SVC(kernel="linear")
fittedsvc = svc.fit(X, y)
        """,
        "model" : """
svc_small_c = SVC(C=0.1)
svc_small_c.fit(X, y)
param_grid = {'C': [0.001, 0.01, 0.1, 1, 5, 10, 100]}
grid_search = GridSearchCV(SVC(), param_grid, cv=5)
grid_search.fit(X, y)

print("Cross-Validation Errors:", grid_search.cv_results_['mean_test_score'])
print("Best Value of C:", grid_search.best_params_['C'])

X_test = np.random.randn(20, 2)

y_pred = grid_search.best_estimator_.predict(X_test)
accuracy = sum(y_pred == [0 if x[0] + x[1] < 0 else 1 for x in X_test]) / len(X_test)
print(f"Accuracy on Test Data: {accuracy*100:.2f}%")

print("Number of Support Vectors:", len(grid_search.best_estimator_.support_vectors_))
        """,
        "plot" : """
def plot_svc_decision_function(model, ax=None, plot_support=True):
    if ax is None:
        ax = plt.gca()
    xlim = ax.get_xlim()
    ylim = ax.get_ylim()

    # create grid to evaluate model
    x = np.linspace(xlim[0], xlim[1], 30)
    y = np.linspace(ylim[0], ylim[1], 30)
    Y, X = np.meshgrid(y, x)
    xy = np.vstack([X.ravel(), Y.ravel()]).T
    P = model.decision_function(xy).reshape(X.shape)

    # plot decision boundary and margins
    ax.contour(X, Y, P, colors='k',
               levels=[-1, 0, 1], alpha=0.5,
               linestyles=['--', '-', '--'])

    # plot support vectors
    if plot_support:
        ax.scatter(model.support_vectors_[:, 0],
                   model.support_vectors_[:, 1],
                   s=300, linewidth=1, facecolors='none');
    ax.set_xlim(xlim)
    ax.set_ylim(ylim)

plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')
plot_svc_decision_function(svc)
plt.show()
        """
    }
}

data['KNN']['all'] = '\n'.join(list(data['KNN'].values()))
data['DT']['all'] = '\n'.join(list(data['DT'].values()))
data['SVM']['all'] = '\n'.join(list(data['SVM'].values()))
